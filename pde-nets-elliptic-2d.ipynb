{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKYM-OSfnRDj",
    "tags": []
   },
   "source": [
    "# Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks\n",
    "\n",
    "Code for elliptic problems presented in [*Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks*](https://arxiv.org/abs/2311.00259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKYM-OSfnRDj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "\n",
    "# # Uncomment to set memory growth for GPU\n",
    "# def set_memory_growth():\n",
    "#     # Get GPUs\n",
    "#     gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#     # For tensorflow 2.x.x allow memory growth on GPU\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        \n",
    "# set_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9KB6MRynWa9",
    "tags": []
   },
   "source": [
    "## Get problem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9KB6MRynWa9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set grid size\n",
    "N = 128\n",
    "h = 1./(N - 1)\n",
    "\n",
    "# Define grid\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.linspace(0, 1, N)\n",
    "[X, Y] = np.meshgrid(x, y)\n",
    "\n",
    "# Get problem data\n",
    "# Bubble function\n",
    "u = X*(X - 1)*Y*(Y - 1)\n",
    "f = 2*(X - 1)*X + 2*(Y - 1)*Y\n",
    "\n",
    "# Peak function\n",
    "# u = 0.0005*X**2*(X - 1)**2*Y**2*(Y - 1)**2*np.exp(10*X**2 + 10*Y)\n",
    "# f = 0.0010 * np.exp(10 * X**2 + 10 * Y) * (\n",
    "#     200 * X**6 * Y**4 - 400 * X**6 * Y**3 + 200 * X**6 * Y**2\n",
    "#     - 400 * X**5 * Y**4 + 800 * X**5 * Y**3 - 400 * X**5 * Y**2\n",
    "#     + 340 * X**4 * Y**4 - 640 * X**4 * Y**3 + 286 * X**4 * Y**2\n",
    "#     + 14 * X**4 * Y + X**4 - 240 * X**3 * Y**4 + 400 * X**3 * Y**3\n",
    "#     - 132 * X**3 * Y**2 - 28 * X**3 * Y - 2 * X**3\n",
    "#     + 106 * X**2 * Y**4 - 172 * X**2 * Y**3 + 52 * X**2 * Y**2\n",
    "#     + 14 * X**2 * Y + X**2 - 6 * X * Y**4 + 12 * X * Y**3\n",
    "#     - 6 * X * Y**2 + Y**4 - 2 * Y**3 + Y**2)\n",
    "\n",
    "# Exponential-Trigonometric function\n",
    "# u = np.exp(-X**2 - Y**2) * np.sin(3 * np.pi * X) * np.sin(3 * np.pi * Y) + X\n",
    "# f = -2 * np.exp(-X**2 - Y**2) * (\n",
    "#         6 * np.pi * Y * np.cos(3 * np.pi * Y) * np.sin(3 * np.pi * X) +\n",
    "#         (6 * np.pi * X * np.cos(3 * np.pi * X) +\n",
    "#          (9 * np.pi**2 - 2 * (-1 + X**2 + Y**2)) * np.sin(3 * np.pi * X)) * np.sin(3 * np.pi * Y))\n",
    "\n",
    "# Get boundary data\n",
    "g = [u[:, 0], u[:, -1], u[0, :], u[-1, :]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROxHDL4IpKM1",
    "tags": []
   },
   "source": [
    "## Define loss function for elliptic problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROxHDL4IpKM1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "class FDLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, N, f, g, **kwargs):\n",
    "        super(FDLoss, self).__init__(**kwargs)\n",
    "        self.N = N\n",
    "        self.h = 1./(N - 1)\n",
    "        self.alpha = np.square(0.5*self.h)\n",
    "\n",
    "        # Set up right hand side\n",
    "        self.f = tf.constant(f, dtype=tf.float32)\n",
    "        self.f = tf.reshape(f, [1, N, N, 1])\n",
    "        self.f = tf.cast(self.f, tf.float32)\n",
    "\n",
    "        # Set up finite difference kernel\n",
    "        k_laplacian = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]) / np.square(self.h)\n",
    "        k_laplacian = tf.constant(k_laplacian, dtype=tf.float32)\n",
    "        self.k_laplacian = tf.reshape(k_laplacian, [3, 3, 1, 1])\n",
    "\n",
    "        # Define boundary terms\n",
    "        self.g = [tf.cast(g[i], tf.float32) for i in range(4)]\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Loss on interior\n",
    "        rhs = -tf.nn.convolution(y_pred, self.k_laplacian, strides=1)\n",
    "        interior = tf.reduce_mean(tf.square(rhs + self.f[:, 1:-1, 1:-1, :]))\n",
    "\n",
    "        # Get boundary values for left, right, bottom, and top\n",
    "        left_boundary = tf.square(self.g[0] - tf.reshape(y_pred[:, :, 0, :], [self.N]))\n",
    "        right_boundary = tf.square(self.g[1] - tf.reshape(y_pred[:, :, -1, :], [self.N]))\n",
    "        bottom_boundary = tf.square(self.g[2] - tf.reshape(y_pred[:, 0, :, :], [self.N]))\n",
    "        top_boundary = tf.square(self.g[3] - tf.reshape(y_pred[:, -1, :, :], [self.N]))\n",
    "\n",
    "        # Define boundary loss for left, right, bottom, and top boundaries\n",
    "        boundary = tf.concat([left_boundary,\n",
    "                              right_boundary,\n",
    "                              bottom_boundary,\n",
    "                              top_boundary], axis = -1)\n",
    "        boundary = tf.reduce_mean(boundary)\n",
    "\n",
    "        # Compute final loss\n",
    "        loss = self.alpha*interior + (1. - self.alpha)*boundary\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMnstLfevL_H",
    "tags": []
   },
   "source": [
    "## Build U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMnstLfevL_H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_norm(name):\n",
    "    if \"batch\" in name:\n",
    "        return tf.keras.layers.BatchNormalization(axis=-1, center=True, scale=True)\n",
    "    elif \"identity\" in name:\n",
    "        return tf.identity\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization layer\")\n",
    "\n",
    "\n",
    "def get_regularizer(name):\n",
    "    if \"l2\" in name:\n",
    "        return tf.keras.regularizers.L2(1e-7)\n",
    "    elif \"none\" in name:\n",
    "        return None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid regularization layer\")\n",
    "\n",
    "\n",
    "def get_activation(name, **kwargs):\n",
    "    if name == \"relu\":\n",
    "        return tf.keras.layers.ReLU()\n",
    "    elif name == \"leaky\":\n",
    "        return tf.keras.layers.LeakyReLU(alpha=kwargs[\"alpha\"])\n",
    "    elif name == \"prelu\":\n",
    "        return tf.keras.layers.PReLU(shared_axes=[1, 2])\n",
    "    elif name == \"identity\":\n",
    "        return tf.identity\n",
    "    else:\n",
    "        raise ValueError(\"Invalid activation layer\")\n",
    "\n",
    "\n",
    "class ConvDownsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=kwargs[\"filters\"],\n",
    "                                           kernel_size=3,\n",
    "                                           strides=2,\n",
    "                                           kernel_regularizer=get_regularizer(kwargs[\"regularizer\"]))\n",
    "        self.norm = get_norm(kwargs[\"norm\"])\n",
    "        self.activation = get_activation(kwargs[\"activation\"], **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_downsample(name, **kwargs):\n",
    "    if name == 'maxpool':\n",
    "        return tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "    elif name == \"avgpool\":\n",
    "        return tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "    elif name == 'conv':\n",
    "        return ConvDownsample(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid downsampling operation\")\n",
    "\n",
    "class ConvLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                           kernel_size=5,\n",
    "                                           padding=\"same\",\n",
    "                                           kernel_regularizer=get_regularizer(kwargs[\"regularizer\"]))\n",
    "        self.norm = get_norm(kwargs[\"norm\"])\n",
    "        self.activation = get_activation(kwargs[\"activation\"], **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block(filters, **kwargs)\n",
    "        self.down = get_downsample(kwargs[\"down_type\"], filters=filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        skip = self.block(x)\n",
    "        x = self.down(skip)\n",
    "        return skip, x\n",
    "\n",
    "\n",
    "class Bottleneck(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block(filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        self.upsample = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")\n",
    "        self.block = block(filters, **kwargs)\n",
    "\n",
    "    def call(self, skip, x):\n",
    "        up = self.upsample(x)\n",
    "        concat = tf.keras.layers.concatenate([skip, up])\n",
    "        out = self.block(concat)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BaseModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 n_classes,\n",
    "                 init_filters,\n",
    "                 depth,\n",
    "                 pocket,\n",
    "                 **kwargs):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        # User defined inputs\n",
    "        self.n_classes = n_classes\n",
    "        self.init_filters = init_filters\n",
    "        self.depth = depth\n",
    "        self.pocket = pocket\n",
    "\n",
    "        # If pocket network, do not double feature maps after downsampling\n",
    "        self.mul_on_downsample = 2\n",
    "        if self.pocket:\n",
    "            self.mul_on_downsample = 1\n",
    "\n",
    "        self.encoder = list()\n",
    "        for i in range(self.depth):\n",
    "            filters = self.init_filters * self.mul_on_downsample ** i\n",
    "            self.encoder.append(EncoderBlock(filters, block, **kwargs))\n",
    "\n",
    "        filters = self.init_filters * self.mul_on_downsample ** self.depth\n",
    "        self.bottleneck = Bottleneck(filters, block, **kwargs)\n",
    "\n",
    "        self.decoder = list()\n",
    "        for i in range(self.depth - 1, -1, -1):\n",
    "            filters = self.init_filters * self.mul_on_downsample ** i\n",
    "            self.decoder.append(DecoderBlock(filters, block, **kwargs))\n",
    "\n",
    "        self.out = tf.keras.layers.Conv2D(self.n_classes, 1, padding=\"same\", dtype=\"float32\")\n",
    "\n",
    "    def call(self, x):\n",
    "        skips = list()\n",
    "        for encoder_block in self.encoder:\n",
    "            skip, x = encoder_block(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        skips.reverse()\n",
    "        for skip, decoder_block in zip(skips, self.decoder):\n",
    "            x = decoder_block(skip, x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "conv_kwargs = {\"regularizer\": \"l2\",\n",
    "               \"norm\": \"identity\",\n",
    "               \"activation\": \"identity\",\n",
    "               \"alpha\": 0.01,\n",
    "               \"down_type\": \"maxpool\"}\n",
    "\n",
    "\n",
    "class UNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(filters, **kwargs)\n",
    "        self.conv2 = ConvLayer(filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class UNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 init_filters,\n",
    "                 depth,\n",
    "                 pocket):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.base_model = BaseModel(UNetBlock,\n",
    "                                    n_classes,\n",
    "                                    init_filters,\n",
    "                                    depth,\n",
    "                                    pocket,\n",
    "                                    **conv_kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, **kwargs):\n",
    "        return self.base_model(x, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFjev4FKyoJ2",
    "outputId": "eee97eea-cbaa-433b-b202-f43b0d46df9e",
    "tags": []
   },
   "source": [
    "## Put it all together\n",
    "\n",
    "* Instantiate loss function and network\n",
    "* Define training step\n",
    "* Begin unsupervised training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFjev4FKyoJ2",
    "outputId": "eee97eea-cbaa-433b-b202-f43b0d46df9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = FDLoss(N, f, g)\n",
    "\n",
    "n_steps = 2000\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=n_steps\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
    "optimizer.global_clipnorm = 0.001\n",
    "\n",
    "model = UNet(1, 32, 3, True)\n",
    "\n",
    "inp = f.reshape(1, N, N, 1)\n",
    "\n",
    "prog_bar = Progbar(n_steps, stateful_metrics=['loss'])\n",
    "\n",
    "@tf.function\n",
    "def train_step(input):\n",
    "    with tf.GradientTape() as tape:\n",
    "        p = model(inp)\n",
    "        loss = loss_fn(p, p)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, p\n",
    "\n",
    "best = np.Inf\n",
    "best_p = np.zeros((1, N, N, 1))\n",
    "for step in range(n_steps):\n",
    "    loss, p = train_step(input)\n",
    "    prog_bar.add(1, values=[('loss', loss)])\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_p = p\n",
    "\n",
    "pred = best_p.numpy().reshape(N, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-b_T7DaF-v1m",
    "outputId": "5f7898ae-5b96-4922-fe47-40bd5aced18d",
    "tags": []
   },
   "source": [
    "## Compute error and plot solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-b_T7DaF-v1m",
    "outputId": "5f7898ae-5b96-4922-fe47-40bd5aced18d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"L2 error: {}\".format(np.format_float_scientific(h*np.sqrt(np.sum(np.square(u - pred))), 4)))\n",
    "print(\"L-inf error: {}\".format(np.format_float_scientific(np.max(np.abs(u - pred)), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "XQpkf3XdLGe6",
    "outputId": "403d2a20-f372-4d40-9431-e053ddf38aee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create figure and subplots\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "\n",
    "# Plot true solution\n",
    "contour1 = axs[0].imshow(u)\n",
    "axs[0].set_title(\"True Solution\")\n",
    "cbar1 = fig.colorbar(contour1, ax=axs[0])\n",
    "\n",
    "# Plot prediction\n",
    "contour1 = axs[1].imshow(pred)\n",
    "axs[1].set_title(\"Prediction\")\n",
    "cbar1 = fig.colorbar(contour1, ax=axs[1])\n",
    "\n",
    "# Plot difference\n",
    "contour3 = axs[2].imshow(np.abs(u - pred))\n",
    "axs[2].set_title(\"Difference\")\n",
    "cbar3 = fig.colorbar(contour3, ax=axs[2])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

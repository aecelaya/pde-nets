{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHAlqRG7JG0x",
    "tags": []
   },
   "source": [
    "# Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks\n",
    "\n",
    "Code for parabolic problems presented in [*Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks*](https://arxiv.org/abs/2311.00259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHAlqRG7JG0x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Progbar\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import Image\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# # Uncomment to set memory growth for GPU\n",
    "# def set_memory_growth():\n",
    "#     # Get GPUs\n",
    "#     gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#     # For tensorflow 2.x.x allow memory growth on GPU\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        \n",
    "# set_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGWROndLJLwQ",
    "tags": []
   },
   "source": [
    "## Get problem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGWROndLJLwQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define grid size and time step\n",
    "N = 128\n",
    "h = 1/(N - 1)\n",
    "time_step = 0.1\n",
    "\n",
    "# Define grid\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.linspace(0, 1, N)\n",
    "[X, Y] = np.meshgrid(x, y)\n",
    "\n",
    "# Trigonometric functions (we used n = 1 and n = 4)\n",
    "n = 1\n",
    "u = lambda t: tf.constant((np.cos(t) * np.sin(n * np.pi * X) * np.sin(n * np.pi * Y)).reshape(1, N, N, 1), dtype=tf.float32)\n",
    "f = lambda t: tf.constant((-np.sin(n*np.pi*X)*np.sin(n*np.pi*Y)*(-2*np.cos(t)*n**2*np.pi**2 + np.sin(t))).reshape(1, N, N, 1), dtype=tf.float32)\n",
    "\n",
    "# Gaussian function\n",
    "# u = lambda t: tf.constant((np.exp(-50*((2*X - 1)**2 + (2*Y - 1)**2)) * np.cos(t)).reshape(1, N, N, 1), dtype=tf.float32)\n",
    "# f = lambda t: tf.constant((-np.exp(-50*(2*X - 1)**2 - 50*(2*Y - 1)**2)*(160000*np.cos(t)*X**2 - 160000*np.cos(t)*X + 160000*np.cos(t)*Y**2 - 160000*np.cos(t)*Y + 79200*np.cos(t) + np.sin(t))).reshape(1, N, N, 1), dtype=tf.float32)\n",
    "\n",
    "# # Initial condition\n",
    "u0 = u(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoUnfoIyJu6j",
    "tags": []
   },
   "source": [
    "## Define time dependent loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoUnfoIyJu6j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "class TimeDependentLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, N, step_size, f, **kwargs):\n",
    "        super(TimeDependentLoss, self).__init__(**kwargs)\n",
    "        self.N = N\n",
    "        self.h = 1./(N - 1.)\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        # Tune this parameter\n",
    "        self.alpha = np.square(self.h) * 4\n",
    "        \n",
    "        # Get source term\n",
    "        self.f = f\n",
    "\n",
    "        # Set up kernels\n",
    "        # Laplacian kernel\n",
    "        k_laplacian = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]) / np.square(self.h)\n",
    "        k_laplacian = tf.constant(k_laplacian, dtype=tf.float32)\n",
    "        self.k_laplacian = tf.reshape(k_laplacian, [3, 3, 1, 1])\n",
    "\n",
    "    def call(self, current_previous, t):\n",
    "\n",
    "        # Unpack current and previous predictions\n",
    "        u_current, u_previous = current_previous\n",
    "        \n",
    "        # Get value of f at time t\n",
    "        f_current = self.f(t)[:, 1:-1, 1:-1, :]\n",
    "        \n",
    "        # Loss on interior\n",
    "        u_current_interior = u_current[:, 1:-1, 1:-1, :]\n",
    "        u_previous_interior = u_previous[:, 1:-1, 1:-1, :]\n",
    "\n",
    "        # Estimate right hand side (i.e., laplacian(u)) for current step\n",
    "        rhs = tf.nn.convolution(u_current, self.k_laplacian, strides=1)\n",
    "\n",
    "        interior = tf.reduce_mean(tf.square(u_current_interior - u_previous_interior - self.step_size*(rhs + f_current)))\n",
    "\n",
    "        # Loss on boundary\n",
    "        # Get boundary values for left, right, bottom, and top\n",
    "        left_boundary = tf.square(tf.reshape(u_current[:, :, 0, :], [self.N]))\n",
    "        right_boundary = tf.square(tf.reshape(u_current[:, :, -1, :], [self.N]))\n",
    "        bottom_boundary = tf.square(tf.reshape(u_current[:, 0, :, :], [self.N]))\n",
    "        top_boundary = tf.square(tf.reshape(u_current[:, -1, :, :], [self.N]))\n",
    "\n",
    "        # # Define boundary loss for left, right, bottom, and top boundaries\n",
    "        boundary = tf.concat([left_boundary,\n",
    "                              right_boundary,\n",
    "                              bottom_boundary,\n",
    "                              top_boundary], axis = -1)\n",
    "        boundary = tf.reduce_mean(boundary)\n",
    "\n",
    "        # Compute final loss\n",
    "        loss = self.alpha*interior + (1 - self.alpha)*boundary\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT0-pz77LtPL",
    "tags": []
   },
   "source": [
    "## Build U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT0-pz77LtPL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_norm(name):\n",
    "    if \"batch\" in name:\n",
    "        return tf.keras.layers.BatchNormalization(axis=-1, center=True, scale=True)\n",
    "    elif \"identity\" in name:\n",
    "        return tf.identity\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization layer\")\n",
    "\n",
    "\n",
    "def get_regularizer(name):\n",
    "    if \"l2\" in name:\n",
    "        return tf.keras.regularizers.L2(1e-7)\n",
    "    elif \"none\" in name:\n",
    "        return None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid regularization layer\")\n",
    "\n",
    "\n",
    "def get_activation(name, **kwargs):\n",
    "    if name == \"relu\":\n",
    "        return tf.keras.layers.Activation(\"relu\")\n",
    "    elif name == \"tanh\":\n",
    "        return tf.keras.layers.Activation(\"tanh\")\n",
    "    elif name == \"swish\":\n",
    "        return tf.keras.layers.Activation(\"swish\")\n",
    "    elif name == \"identity\":\n",
    "        return tf.identity\n",
    "    else:\n",
    "        raise ValueError(\"Invalid activation layer\")\n",
    "\n",
    "\n",
    "class ConvDownsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=kwargs[\"filters\"],\n",
    "                                           kernel_size=3,\n",
    "                                           strides=2,\n",
    "                                           kernel_regularizer=get_regularizer(kwargs[\"regularizer\"]))\n",
    "        self.norm = get_norm(kwargs[\"norm\"])\n",
    "        self.activation = get_activation(kwargs[\"activation\"], **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_downsample(name, **kwargs):\n",
    "    if name == 'maxpool':\n",
    "        return tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "    elif name == 'avgpool':\n",
    "        return tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "    elif name == 'conv':\n",
    "        return ConvDownsample(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid downsampling layer!\")\n",
    "\n",
    "class ConvLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                           kernel_size=5,\n",
    "                                           padding=\"same\",\n",
    "                                           kernel_regularizer=get_regularizer(kwargs[\"regularizer\"]))\n",
    "        self.norm = get_norm(kwargs[\"norm\"])\n",
    "        self.activation = get_activation(kwargs[\"activation\"], **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block(filters, **kwargs)\n",
    "        self.down = get_downsample(kwargs[\"down_type\"], filters=filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        skip = self.block(x)\n",
    "        x = self.down(skip)\n",
    "        return skip, x\n",
    "\n",
    "\n",
    "class Bottleneck(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block(filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, block, **kwargs):\n",
    "        super().__init__()\n",
    "        # self.trans_conv = tf.keras.layers.Conv2DTranspose(filters=filters,\n",
    "        #                                                   kernel_size=2,\n",
    "        #                                                   strides=2)\n",
    "        self.upsample = tf.keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.block = block(filters, **kwargs)\n",
    "\n",
    "    def call(self, skip, x):\n",
    "        up = self.upsample(x)\n",
    "        concat = tf.keras.layers.concatenate([skip, up])\n",
    "        out = self.block(concat)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvLSTMBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, return_sequences, **kwargs):\n",
    "        super().__init__()\n",
    "        self.convlstm = tf.keras.layers.ConvLSTM2D(filters=filters,\n",
    "                                                   kernel_size=5,\n",
    "                                                   padding='same',\n",
    "                                                   return_sequences=return_sequences)\n",
    "        self.norm = get_norm(kwargs[\"norm\"])\n",
    "        self.activation = get_activation(kwargs[\"activation\"], **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.convlstm(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaseModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 n_classes,\n",
    "                 init_filters,\n",
    "                 depth,\n",
    "                 pocket,\n",
    "                 **kwargs):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        # User defined inputs\n",
    "        self.n_classes = n_classes\n",
    "        self.init_filters = init_filters\n",
    "        self.depth = depth\n",
    "        self.pocket = pocket\n",
    "\n",
    "        # If pocket network, do not double feature maps after downsampling\n",
    "        self.mul_on_downsample = 2\n",
    "        if self.pocket:\n",
    "            self.mul_on_downsample = 1\n",
    "            \n",
    "        # self.merge_block = block(self.init_filters, **kwargs)\n",
    "\n",
    "        self.encoder = list()\n",
    "        for i in range(self.depth):\n",
    "            filters = self.init_filters * self.mul_on_downsample ** i\n",
    "            self.encoder.append(EncoderBlock(filters, block, **kwargs))\n",
    "\n",
    "        filters = self.init_filters * self.mul_on_downsample ** self.depth\n",
    "        self.bottleneck = Bottleneck(filters, block, **kwargs)\n",
    "\n",
    "        self.decoder = list()\n",
    "        for i in range(self.depth - 1, -1, -1):\n",
    "            filters = self.init_filters * self.mul_on_downsample ** i\n",
    "            self.decoder.append(DecoderBlock(filters, block, **kwargs))\n",
    "\n",
    "        self.out = tf.keras.layers.Conv2D(n_classes, kernel_size=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        skips = list()\n",
    "        for encoder_block in self.encoder:\n",
    "            skip, x = encoder_block(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        skips.reverse()\n",
    "        for skip, decoder_block in zip(skips, self.decoder):\n",
    "            x = decoder_block(skip, x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "conv_kwargs = {\"regularizer\": \"l2\",\n",
    "               \"norm\": \"identity\",\n",
    "               \"activation\": \"identity\",\n",
    "               \"alpha\": 0.01,\n",
    "               \"down_type\": \"maxpool\"}\n",
    "\n",
    "\n",
    "class UNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(filters, **kwargs)\n",
    "        self.conv2 = ConvLayer(filters, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class UNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 init_filters,\n",
    "                 depth,\n",
    "                 pocket):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.base_model = BaseModel(UNetBlock,\n",
    "                                    n_classes,\n",
    "                                    init_filters,\n",
    "                                    depth,\n",
    "                                    pocket,\n",
    "                                    **conv_kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, **kwargs):\n",
    "        return self.base_model(x, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIa4xKUXLvfG",
    "outputId": "99f43e73-25ff-4d40-b23d-bcee58002c4c",
    "tags": []
   },
   "source": [
    "## Put it all together\n",
    "\n",
    "* Instantiate loss function and network\n",
    "* Define training step\n",
    "* Begin unsupervised training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIa4xKUXLvfG",
    "outputId": "99f43e73-25ff-4d40-b23d-bcee58002c4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = TimeDependentLoss(N, time_step, f)\n",
    "\n",
    "u_previous = u0\n",
    "_n_steps = 250\n",
    "model = UNet(1, 32, 3, True)\n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    first_decay_steps=_n_steps,\n",
    "    t_mul=1.0,\n",
    "    m_mul=1.0,\n",
    "    alpha=0.0\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
    "optimizer.global_clipnorm = 0.001\n",
    "\n",
    "@tf.function\n",
    "def train_step(u_previous, f, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        p = model(u_previous)\n",
    "        loss = loss_fn((p, u_previous), t)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, p\n",
    "\n",
    "sol = list()\n",
    "sol.append(u_previous.numpy().reshape(N, N))\n",
    "\n",
    "for t in range(10):\n",
    "    best = np.Inf\n",
    "    if t == 0:\n",
    "        n_steps = 4*_n_steps\n",
    "    else:\n",
    "        n_steps = _n_steps\n",
    "\n",
    "    prog_bar = Progbar(n_steps, stateful_metrics=[\"time_ste\", \"loss\"])\n",
    "    for step in range(n_steps):\n",
    "        loss, u_candidate = train_step(u_previous, f, time_step*(1 + t))\n",
    "        prog_bar.add(1, values=[(\"time_step\", int(t + 1)), (\"loss\", loss)])\n",
    "\n",
    "        if loss < best:\n",
    "            best = loss\n",
    "            u_next = u_candidate\n",
    "\n",
    "    u_previous = u_next\n",
    "    sol.append(u_next.numpy().reshape(N, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "lkmmhql3PxBK",
    "outputId": "20418231-33aa-484b-d26b-dfd49a2c9067",
    "tags": []
   },
   "source": [
    "## Compute error and plot solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "lkmmhql3PxBK",
    "outputId": "20418231-33aa-484b-d26b-dfd49a2c9067",
    "tags": []
   },
   "outputs": [],
   "source": [
    "step = 5\n",
    "print(\"{}\".format(np.format_float_scientific(h*np.sqrt(np.sum(np.square(u(time_step * step).numpy().reshape(N, N) - sol[step]))), 4)))\n",
    "print(\"{}\".format(np.format_float_scientific(np.max(np.abs(u(time_step * step).numpy().reshape(N, N) - sol[step])), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "lkmmhql3PxBK",
    "outputId": "20418231-33aa-484b-d26b-dfd49a2c9067",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(17, 8), sharey=True, sharex=True)\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "current_time = 0.0\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 10:\n",
    "        # im = ax.imshow(u(time_step * i).numpy().reshape(N, N), cmap=\"jet\", vmin=0, vmax=1, extent=[0, 1, 0, 1])\n",
    "        im = ax.imshow(sol[i], cmap=\"jet\", vmin=0, vmax=1, extent=[0, 1, 0, 1])\n",
    "        # im = ax.imshow(np.abs(u(time_step * i).numpy().reshape(N, N) - sol[i]), cmap=\"jet\", extent=[0, 1, 0, 1])\n",
    "       \n",
    "        \n",
    "        ax.set_title(f\"t = {np.round(current_time, 4)}\", fontsize=20)\n",
    "        \n",
    "        xticks = ax.get_xticks()\n",
    "        ax.set_xticks([xticks[0], xticks[-1]])\n",
    "        ax.set_xticklabels([int(xticks[0]), int(xticks[-1])])\n",
    "        \n",
    "        yticks = ax.get_yticks()\n",
    "        ax.set_yticks([yticks[0], yticks[-1]])\n",
    "        ax.set_yticklabels([int(yticks[0]), int(yticks[-1])])\n",
    "        \n",
    "    # ax.axis('off')\n",
    "    current_time += time_step\n",
    "\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.91, 0.15, 0.05, 0.7])\n",
    "ticklabs = cbar_ax.get_yticklabels()\n",
    "cbar_ax.set_yticklabels(ticklabs, fontsize=20)\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "# fig.text(0.08, 0.5, r'True solution at time $t$, $u^t$', va='center', rotation='vertical', fontsize=20)\n",
    "fig.text(0.08, 0.5, r'Prediction at time $t$, $p^t$', va='center', rotation='vertical', fontsize=20)\n",
    "# fig.text(0.08, 0.5, r'Difference, $|u^t - p^t|$', va='center', rotation='vertical', fontsize=20)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWDciOcJs_rt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gif(array_list, filename='animation.gif'):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(array_list[0], cmap=\"jet\")\n",
    "\n",
    "    def update(num):\n",
    "        im.set_data(array_list[num])\n",
    "        return im\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(array_list), repeat=True)\n",
    "    anim.save(filename, writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "gdAMmh5dyrVZ",
    "outputId": "12c30842-28dd-4548-9739-89908628f92f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_gif(sol, filename='animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "5CGMZQ20UWs5",
    "outputId": "e34321c0-396b-486c-abcf-f10ef7528a81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(filename='animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wybj7ggaZT6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_surface_gif(array_list, filename='animation.gif', cmap='jet'):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_zlim(-0.1, 1.1)\n",
    "\n",
    "    N = array_list[0].shape[0]\n",
    "    X = np.linspace(0, 1, N)\n",
    "    Y = np.linspace(0, 1, N)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    surf = ax.plot_surface(X, Y, array_list[0], cmap=cmap, rstride=1, cstride=1, linewidth=0, antialiased=False)\n",
    "\n",
    "    def update(num):\n",
    "        ax.clear()\n",
    "        surf = ax.plot_surface(X, Y, array_list[num], cmap=cmap, rstride=1, cstride=1, linewidth=0, antialiased=False)\n",
    "        ax.set_zlim(-1.1, 1.1)\n",
    "        return surf,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=len(array_list), interval=100, blit=True, repeat=True)\n",
    "    anim.save(filename, writer='pillow', fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "MMV5-8F7KRhX",
    "outputId": "1587db56-9e19-4935-e890-fd8c16ea4251",
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_surface_gif(sol, filename='animation_3d.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "pEkNIOAVXO6k",
    "outputId": "099fe4bf-1e38-4473-87fc-68fc9211a756",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(filename='animation_3d.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpNz0DFy1FSP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
